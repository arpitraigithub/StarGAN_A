{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Referenced the code from https://github.com/hoangthang1607/StarGAN-Keras/blob/master/StarGAN.py\n",
    "## and https://github.com/yunjey/stargan/\n",
    "## utils.py is for preprocessing of the input image and has been borrowed from \n",
    "## https://github.com/hoangthang1607/StarGAN-Keras/blob/master/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the cifar10 dataset\n",
    "from keras.datasets.cifar10 import load_data\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, UpSampling2D, ZeroPadding2D, Concatenate, Dropout, LeakyReLU, BatchNormalization, ReLU, Conv2DTranspose, Add\n",
    "from keras.layers import Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.models import Model, load_model\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers.merge import _Merge\n",
    "from keras import backend as K\n",
    "from functools import partial\n",
    "# example of training the discriminator model on real and random cifar10 images\n",
    "import numpy\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from skimage.transform import resize\n",
    "from scipy.linalg import sqrtm\n",
    "import matplotlib.pyplot as pyplot\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    # Given in paper, Section 4.1 Implementation of the paper in which the x is to be \n",
    "    # sampled uniformly along a stright line between a pair of real and generated images\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def define_batch_size(self, bs):\n",
    "        self.bs = bs\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((4, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very deep neural networks are hard to train as they are more prone to vanishing or exploding gradients. \n",
    "# To solve this problem, the activation unit from a layer could be fed directly to a deeper layer of the network, \n",
    "# which is termed as a skip connection.\n",
    "\n",
    "def residual_block(inp, dim_out):\n",
    "    x = ZeroPadding2D(padding = 1)(inp)\n",
    "    x = Conv2D(dim_out, kernel_size = (3,3), strides=(1,1), padding='valid', bias= False)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = ZeroPadding2D(padding = 1)(x)\n",
    "    x = Conv2D(dim_out, kernel_size = (3,3), strides=(1,1), padding='valid', bias= False)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    return Add()([inp, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(conv_dim=64, repeat_num=6, image_size = 128, c_dim = 5):\n",
    "    generator = Sequential()\n",
    "    #input_domain is the domain labels of the attruites ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "    input_domain = Input(shape = (c_dim, ))\n",
    "    #input image size of 128 X 128\n",
    "    input_image = Input(shape = (image_size, image_size, 3))   \n",
    "    # Concatanating the domain information with the image\n",
    "    c = Lambda(lambda x: K.repeat(x, image_size**2))(input_domain)\n",
    "    c = Reshape((image_size, image_size, c_dim))(c)\n",
    "    x = Concatenate()([input_image, c])\n",
    "    #the model is prepared as per the model summart given in the paper\n",
    "    # starting with the first convolution\n",
    "    x = Conv2D(conv_dim, kernel_size = (7,7), strides=(1,1), padding='same', bias=False)(x)\n",
    "    x = InstanceNormalization(axis = -1)(x)\n",
    "    x = ReLU()(x)\n",
    "    curr_dim = conv_dim\n",
    "    for i in range(2):\n",
    "        x = ZeroPadding2D(padding = 1)(x)\n",
    "        x = Conv2D(curr_dim*2, kernel_size=(4,4), strides=(2,2), padding='valid', bias=False)(x)\n",
    "        x = InstanceNormalization(axis = -1)(x)\n",
    "        x = ReLU()(x)\n",
    "        curr_dim = curr_dim * 2\n",
    "    # Bottleneck layers.\n",
    "    for i in range(repeat_num):\n",
    "        x = residual_block(inp=x, dim_out=curr_dim)\n",
    "    # Up-sampling layers.\n",
    "    for i in range(2):\n",
    "        x = UpSampling2D(size = 2)(x)\n",
    "        x = Conv2D(curr_dim//2, kernel_size=(4,4), strides=(1,1), padding='same', bias=False)(x)\n",
    "        x = InstanceNormalization(axis = -1)(x)\n",
    "        x = ReLU()(x)\n",
    "        curr_dim = curr_dim // 2\n",
    "    x = ZeroPadding2D(padding = 3)(x)\n",
    "    o = Conv2D(filters = 3, kernel_size = 7, strides = 1, padding = 'valid', activation = 'tanh', use_bias = False)(x)\n",
    "    return Model(inputs = [input_image, input_domain], outputs = o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(in_shape=(128,128,3), conv_dim=64, image_size=128, repeat_num=6, c_dim=5):\n",
    "    #input dimension of the input image\n",
    "    input_image = Input(shape = (image_size, image_size, 3))\n",
    "    #first layer of convolution\n",
    "    x = ZeroPadding2D(padding = 1)(input_image)\n",
    "    x = Conv2D(filters = conv_dim, kernel_size = (4,4), strides = (2,2), padding = 'valid', use_bias = False)(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    curr_dim = conv_dim\n",
    "    for i in range(1, repeat_num):\n",
    "        x = ZeroPadding2D(padding = 1)(x)\n",
    "        x = Conv2D(filters = curr_dim*2, kernel_size = (4,4), strides = (2,2), padding = 'valid')(x)\n",
    "        x = LeakyReLU(alpha=0.01)(x)\n",
    "        curr_dim = curr_dim * 2\n",
    "    kernel_size = int(image_size / numpy.power(2, repeat_num))\n",
    "    out_src = ZeroPadding2D(padding = 1)(x)\n",
    "    out_src = Conv2D(filters = 1, kernel_size = (3,3), strides = (1,1), padding= 'valid', use_bias = False)(out_src)\n",
    "    out_cls = Conv2D(filters = c_dim, kernel_size = kernel_size, strides = (1,1), padding= 'valid', use_bias = False)(x)\n",
    "    out_cls = Reshape((c_dim, ))(out_cls)\n",
    "    return Model(input_image, [out_src, out_cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed the code from https://www.programcreek.com/python/example/90401/tensorflow.divide\n",
    "def classification_loss(Y_true, Y_pred) :\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y_true, logits=Y_pred))\n",
    "\n",
    "    \n",
    "def wasserstein_loss(Y_true, Y_pred):\n",
    "    return K.mean(Y_true*Y_pred)\n",
    "\n",
    "#borrowed code from https://danijar.com/building-variational-auto-encoders-in-tensorflow/\n",
    "def reconstruction_loss(Y_true, Y_pred):\n",
    "    return K.mean(K.abs(Y_true - Y_pred))\n",
    "\n",
    "#borrowed code from https://github.com/hoangthang1607/StarGAN-Keras\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    # summing over the rows\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=numpy.arange(1, len(gradients_sqr.shape)))\n",
    "    # and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "lambda_cls = 1\n",
    "lambda_rec = 10\n",
    "image_size = 128\n",
    "batch_size = 4\n",
    "c_dim = 5\n",
    "d_lr = 0.0001\n",
    "g_lr = 0.0001\n",
    "lambda_gp = 10\n",
    "lambda_rec = 10\n",
    "selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "image_size=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train(previous_model = False):\n",
    "    \n",
    "    # declaration of variables\n",
    "    beta_1 = 0.5\n",
    "    beta_2 = 0.999\n",
    "    lambda_cls = 1\n",
    "    lambda_rec = 10\n",
    "    image_size = 128\n",
    "    batch_size = 4\n",
    "    c_dim = 5\n",
    "    d_lr = 0.0001\n",
    "    g_lr = 0.0001\n",
    "    lambda_gp = 10\n",
    "    lambda_rec = 10\n",
    "    previous_iteration = 50500\n",
    "    selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "    model_save_dir = 'model_save/'\n",
    "    model_load_dir = 'model_previous/'\n",
    "    gen = generator()\n",
    "    dis = discriminator()\n",
    "    time_calculate = 100\n",
    "    mode= 'train'\n",
    "    # Only updating the weights of the discriminator and making the genrator trainable False\n",
    "    gen.trainable = False\n",
    "    \n",
    "    # using real image to get the discriminator output\n",
    "    x_real = Input(shape = (image_size, image_size, 3))\n",
    "    out_src_real, out_class_real = dis(x_real)\n",
    "    \n",
    "    \n",
    "    # using fake image to get the output of the discriminator\n",
    "    target_label = Input(shape = (5,))\n",
    "    x_fake = gen([x_real, target_label])\n",
    "    out_src_fake, out_cls_fake = dis(x_fake)\n",
    "    \n",
    "    # where ^x is sampled uniformly along a straight line between a pair of a real and a generated images.\n",
    "    random_average = RandomWeightedAverage()\n",
    "    random_average.define_batch_size(batch_size)\n",
    "    x_bet_line = random_average([x_real, x_fake])\n",
    "    out_src, _ = dis(x_bet_line)\n",
    "    \n",
    "    # Calculating the gradient penalty loss using the partial parameters to the method\n",
    "    partial_gp_loss = partial(gradient_penalty_loss, averaged_samples = x_bet_line)\n",
    "    partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "    \n",
    "    # Defining training model for Discriminator\n",
    "    train_dis = Model([x_real, target_label],[out_src_real, out_class_real, out_src_fake, out_src])\n",
    "    \n",
    "    # load the previous model, load the previous weights for continuation of the training\n",
    "    if previous_model:\n",
    "        train_dis.load_weights(os.path.join(model_load_dir, 'train_dis_weights.hdf5'))\n",
    "    # Loss for discriminator\n",
    "    train_dis.compile(loss = [wasserstein_loss, classification_loss, wasserstein_loss, partial_gp_loss], \n",
    "                    optimizer=Adam(lr = d_lr, beta_1 = beta_1, beta_2 = beta_2), loss_weights=[1,lambda_cls,1,lambda_gp])\n",
    "                    \n",
    "    # Update generator only\n",
    "    gen.trainable = True\n",
    "    dis.trainable = False\n",
    "\n",
    "    # All inputs\n",
    "    real_x = Input(shape = (image_size, image_size, 3))\n",
    "    original_label = Input(shape = (c_dim, ))\n",
    "    target_label = Input(shape = (c_dim, ))\n",
    "\n",
    "    # Generate the image using the generator which is the fake image.\n",
    "    fake_x = gen([real_x, target_label])\n",
    "    fake_out_src, fake_out_cls = dis(fake_x)\n",
    "\n",
    "    # Target-to-original domain.\n",
    "    x_reconst = gen([fake_x, original_label])\n",
    "\n",
    "    # Define traning model G\n",
    "    train_gen = Model([real_x, original_label, target_label], [fake_out_src, fake_out_cls, x_reconst])\n",
    "    \n",
    "    if previous_model:\n",
    "        train_gen.load_weights(os.path.join(model_load_dir, 'train_gen_weights.hdf5'))    \n",
    "    \n",
    "    # Setup loss for train_G\n",
    "    train_gen.compile(loss = [wasserstein_loss, classification_loss, reconstruction_loss], \n",
    "                         optimizer=Adam(lr = g_lr, beta_1 = beta_1, beta_2 = beta_2), loss_weights = [1, lambda_cls, lambda_rec])\n",
    "\n",
    "    \n",
    "    num_iters = 200000\n",
    "    num_iters_decay = 100000\n",
    "    n_critic = 5\n",
    "    log_step = 10\n",
    "    sample_step = 1000\n",
    "    model_save_step = 10000 \n",
    "    lr_update_step = 1000\n",
    "    model_save_dir = 'model_save/'\n",
    "    \n",
    "    # loading the previously saved model of the generator and discriminator\n",
    "    if previous_model:\n",
    "        gen.load_weights(os.path.join(model_load_dir, 'G_weights.hdf5'))\n",
    "        dis.load_weights(os.path.join(model_load_dir, 'D_weights.hdf5')) \n",
    "\n",
    "    #saving the loss and statistics in the csv file\n",
    "    if not os.path.isfile('data.csv'):\n",
    "        with open('data.csv','w') as newFile:\n",
    "            newFileWriter = csv.writer(newFile)\n",
    "            newFileWriter.writerow(['num_iter','loss_real','loss_fake', 'loss_cls', 'loss_gp', 'loss_fake', 'loss_rec', 'loss_cls'])\n",
    "    \n",
    "    # Training of the model\n",
    "    valid = -np.ones((batch_size, 2, 2, 1))\n",
    "    fake =  np.ones((batch_size, 2, 2, 1))\n",
    "    dummy = np.zeros((batch_size, 2, 2, 1)) # Dummy gt for gradient penalty\n",
    "    start = time.time()\n",
    "    # Exception handling of the code, where in case of any error it will restarted from the point where it failed\n",
    "    while previous_iteration <= 200000:\n",
    "        # Loading the training images from the images director inside the celeba directory\n",
    "        Image_data_class = ImageData(data_dir='celeba', selected_attrs=selected_attrs)\n",
    "        # cropping and resizing the image\n",
    "        Image_data_class.preprocess()\n",
    "        # loading the image into the iterator\n",
    "        data_iter = get_loader(Image_data_class.train_dataset, Image_data_class.train_dataset_label, Image_data_class.train_dataset_fix_label, \n",
    "                                   image_size=image_size, batch_size=batch_size, mode=mode)\n",
    "        #starting of the training for 200,000 iterations\n",
    "        try:\n",
    "            for epoch in range(previous_iteration, num_iters):\n",
    "                # this is to estimate the time required to complete all the iterations\n",
    "                done = time.time()\n",
    "                # unpacking the ob;jects from the iterator\n",
    "                imgs, original_labels, target_labels, fix_labels, _ = next(data_iter)\n",
    "\n",
    "                # Setting learning rate, which is the linear decay\n",
    "                if epoch > (num_iters - num_iters_decay):\n",
    "                    K.set_value(train_dis.optimizer.lr, d_lr*(num_iters - epoch)/(num_iters - num_iters_decay))\n",
    "                    K.set_value(train_gen.optimizer.lr, g_lr*(num_iters - epoch)/(num_iters - num_iters_decay))\n",
    "\n",
    "                # Training the Discriminator        \n",
    "                D_loss = train_dis.train_on_batch(x = [imgs, target_labels], y = [valid, original_labels, fake, dummy])\n",
    "\n",
    "                # calculating the loss of the generator\n",
    "                if (epoch + 1) % n_critic == 0:\n",
    "                    G_loss = train_gen.train_on_batch(x = [imgs, original_labels, target_labels], y = [valid, target_labels, imgs])\n",
    "                # printing the loss and statis and putting all the statistics in the csv file\n",
    "                if (epoch + 1) % log_step == 0:\n",
    "                    print(f\"Iteration: [{epoch + 1}/{num_iters}]\")\n",
    "                    print(f\"\\tD/loss_real = [{D_loss[1]:.4f}], D/loss_fake = [{D_loss[3]:.4f}], D/loss_cls =  [{D_loss[2]:.4f}], D/loss_gp = [{D_loss[4]:.4f}]\")\n",
    "                    print(f\"\\tG/loss_fake = [{G_loss[1]:.4f}], G/loss_rec = [{G_loss[3]:.4f}], G/loss_cls = [{G_loss[2]:.4f}]\") \n",
    "                    with open('data.csv', 'a') as newFile:\n",
    "                        newFileWriter = csv.writer(newFile)\n",
    "                        newFileWriter.writerow([epoch+1, D_loss[1], D_loss[3], D_loss[2], D_loss[4], G_loss[1], G_loss[3], G_loss[2]])\n",
    "                # Saving the model which can be utilized later to continue the training\n",
    "                if (epoch + 1) % model_save_step == 0:\n",
    "                    data_iter = get_loader(Image_data_class.test_dataset, Image_data_class.test_dataset_label, Image_data_class.test_dataset_fix_label, \n",
    "                                   image_size=image_size, batch_size=batch_size, mode=mode)        \n",
    "                    n_batches = int(sample_step / batch_size)\n",
    "                    total_samples = n_batches * batch_size\n",
    "                    gen.save_weights(os.path.join(model_save_dir, 'G_weights.hdf5'))\n",
    "                    dis.save_weights(os.path.join(model_save_dir, 'D_weights.hdf5'))\n",
    "                    train_dis.save_weights(os.path.join(model_save_dir, 'train_dis_weights.hdf5'))\n",
    "                    train_gen.save_weights(os.path.join(model_save_dir, 'train_gen_weights.hdf5'))\n",
    "                # Estimating the time completion\n",
    "                if (epoch + 1 ) % time_calculate == 0:\n",
    "                    elapsed = done - start\n",
    "                    print(\"Time per {} iteration is {}\".format(time_calculate,elapsed))\n",
    "                    print(\"Total Time Remaining is {} minutes\".format((((num_iters - epoch+1)/time_calculate)*elapsed)/60) )\n",
    "                    start = time.time()\n",
    "        except:\n",
    "            # to restart the training where it ended\n",
    "            previous_iteration = epoch + 1\n",
    "            for filename in os.listdir(model_save_dir):\n",
    "                shutil.copy( os.path.join(model_save_dir, filename), model_load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(7, 7), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  del sys.path[0]\n",
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, kernel_size=(4, 4), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", use_bias=False)`\n",
      "  import sys\n",
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", use_bias=False)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, kernel_size=(4, 4), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "D:\\Installs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(4, 4), strides=(1, 1), padding=\"same\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Installs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (truncated file: eof = 120143872, sblock->base_addr = 0, stored_eof = 212851720)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-54469aedf3ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbuild_and_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-51e859c8525c>\u001b[0m in \u001b[0;36mbuild_and_train\u001b[1;34m(previous_model)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprevious_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mtrain_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_load_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_gen_weights.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# Setup loss for train_G\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installs\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installs\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installs\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installs\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 120143872, sblock->base_addr = 0, stored_eof = 212851720)"
     ]
    }
   ],
   "source": [
    "build_and_train(previous_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model_save_dir = 'model_save'\n",
    "    sample_step = 1000\n",
    "    # mode is to test because we will not flip the images with probability 0.5\n",
    "    mode = 'test'\n",
    "    image_size = 128\n",
    "    batch_size = 4\n",
    "    result_dir = 'model_result'\n",
    "    selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "    Image_data_class = ImageData(data_dir='celeba', selected_attrs=selected_attrs)\n",
    "    Image_data_class.preprocess()\n",
    "    data_iter = get_loader(Image_data_class.train_dataset, Image_data_class.train_dataset_label, Image_data_class.train_dataset_fix_label, \n",
    "                               image_size=image_size, batch_size=batch_size, mode=mode)\n",
    "    G_weights_dir = os.path.join(model_save_dir, 'G_weights.hdf5')\n",
    "    G = generator()\n",
    "    G.load_weights(G_weights_dir)\n",
    "\n",
    "    # Data iterator\n",
    "    data_iter = get_loader(Image_data_class.test_dataset, Image_data_class.test_dataset_label, Image_data_class.test_dataset_fix_label, \n",
    "                           image_size=image_size, batch_size=batch_size, mode=mode)        \n",
    "    n_batches = int(sample_step / batch_size)\n",
    "    total_samples = n_batches * batch_size\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        imgs, orig_labels, target_labels, fix_labels, names = next(data_iter)\n",
    "        for j in range(batch_size):\n",
    "            preds = G.predict([np.repeat(np.expand_dims(imgs[j], axis = 0), len(selected_attrs), axis = 0), fix_labels[j]])\n",
    "            for k in range(len(selected_attrs)):                    \n",
    "                Image.fromarray((preds[k]*127.5 + 127.5).astype(np.uint8)).save(os.path.join(result_dir, names[j].split(os.path.sep)[-1].split('.')[0] + f'_{k + 1}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
